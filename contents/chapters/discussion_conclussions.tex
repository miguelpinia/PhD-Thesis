\chapter{Discussion and Conclussions}

This thesis delves into the evolution of concurrent computing and the shift from traditional to more flexible approaches when programming concurrent algorithms. The primary objective of this study was to determine whether it is possible to implement meaningful and useful objects using only synchronization mechanisms among the simplest ones without compromising performance in practical settings.

In Chapter~\ref{chapter:4_work-stealing}, the problem of work-stealing was addressed, and the limits of the standard asynchronous Read/Write wait-free, shared memory model were explored. In Chapter~\ref{chapter:5_modular-basket-queues}, the focus shifted towards building objects from a modular perspective while keeping in mind the use of simple synchronization mechanisms. Specifically, a modular queue was built, where some components can be implemented using only Read/Write operations.


In Chapter~\ref{chapter:6_Results} we present an experimental evaluation to measure the performance of the algorithms presented in Chapters~\ref{chapter:4_work-stealing} and~\ref{chapter:5_modular-basket-queues}. For work-stealing, the study reveals that the use of simple mechanisms can compete and even in some cases, outperform state-of-the-art algorithms. In the case of the modular queue, the study reveals that the queue cannot compete directly against the fastest state-of-the-art queues. However, its performance is good enough, and the performance lies in particular implementations of its modules.


\section{\label{sec:experiment-conclussions} Case Study: Work-Stealing}

In Chapter~\ref{chapter:4_work-stealing}, we studied the use of multiplicity applied to work-stealing. We studied two relaxations for work-stealing, called multiplicity and weak multiplicity. Both of them allow a task to be extracted by more than one $\Take/\Steal$ operation, but each process can take the same task at most once; however, the relaxation can arise only in concurrency. For the first relaxation, this property is directly guaranteed by the definition of set-linearizability. The second relaxation follows from the fact that solutions are required to be sequentially-exact. We presented two $\R/\W$, wait-free algorithms for the relaxations, both devoid of \RAW synchronization patterns.
Moreover, the second algorithm is fence-free with constant step complexity. To our knowledge, these are the first algorithms for relaxations of work-stealing having all these properties, evading the known impossibility result~\cite{DBLP_conf_popl_AttiyaGHKMV11} in all their high-level operations. From the theoretical perspective of the consensus number hierarchy~\cite{DBLP_journals_toplas_Herlihy91}, we have thus shown that work-stealing with multiplicity and weak multiplicity lay at the lowest level with objects whose consensus number is one. We also argued that the idempotent work-stealing~\cite{maged.vechev.2009} does not solve either work-stealing with multiplicity or weak multiplicity. Therefore, the relaxations and algorithms proposed here provide stronger guarantees. An experimental evaluation showed that the benefits in the performance of work-stealing with relaxed semantics depend on the type of application and the complexity of the work associated with a task. Therefore, it cannot be guaranteed that relaxations of work-stealing will always lead to improvements.

Viewed collectively, our results show that the simplest synchronization mechanisms suffice to solve non-trivial coordination problems without compromising performance in some practical applications.
% We can conclude, that relaxed work-stealing algorithms enhanced performance in the benchmarks with lightweight tasks. In the case of graph exploration, the FIFO insert/extract policy provided better improvements. In the benchmark with heavy tasks, all algorithms performed equally.

\section{Case Study: Modular Baskets Queue}

In Chapter~\ref{chapter:5_modular-basket-queues}, we adopted a modular approach to building concurrent objects using simple synchronization mechanisms.
% The aim of using a modular design is to enable developers to focus on a small subset of the system's complexity at any given time to deliver new features. They should be able to work in any given module while knowing little about the rest of the system.
 We designed a modular concurrent queue with multi-producer and multi-consumer semantics. We proposed two concurrent objects that act as modules for the modular queue: baskets and \LL/\IC objects. The baskets contain groups of items that were enqueued concurrently and can be dequeued in any order. The \LL/\IC objects store the head and tail of the queue and allow concurrent manipulation of the enqueues and dequeues.

We introduced a general modular basket queue algorithm that utilizes an infinite array of basket objects along with two \LL/\IC objects to store the head and the tail. Two different \LL/\IC implementations were presented, one that relies solely on \R/\W operations and another that utilizes the \CAS instruction. In addition, we presented two distinct basket implementations. The first implementation follows an approach similar to the LCRQ algorithm by Morrison and Afek~\cite{ppopp2013x86queues}. In contrast, the second is reminiscent of locally generic data structure implementations based on the work of Henzinger et al.~\cite{DBLP_conf_concur_HaasHHKLPSSV16}. However, since the first approach of this modular queue was designed using infinite arrays, we presented a second approach that takes into account the problem that a realistic implementation will not rely on infinite arrays. Therefore, two queue variants were presented: a dynamic array version and a list-of-arrays version.

The results of an experimental evaluation revealed that the most efficient approach for implementing the modular queue was using the \CAS-based \LL/\IC object with the K-basket. With respect to the version of Read/Write, this one was slightly less performant. Comparing the modular queue against state-of-the-art queues shows that the queue cannot directly compete with the fastest queues. However, its performance is still good enough, showing that the performance of the modular queue lies in particular implementations of its modules. This last comes from evaluating three distinct implementations of the modular queue. The first was implementing the first approach with minimal changes, and the other two were based on the variants mentioned at the end of the previous paragraph. Results showed that the first approach and the list-of-arrays version had better performance, with the latter being the best performant. The version based on dynamic arrays does not scale as well as expected.

Viewed collectively, our results show that modular and concurrent algorithms can be built whose performance depends only on the performance of the algorithm's modules. They also show that a simple synchronization mechanism can still be used to develop such algorithms.

\section{Future Research}

The study of the simplest synchronization mechanisms to solve concurrency problems is an ongoing field of research. Attiya, et al.'s work~\cite{DBLP_conf_popl_AttiyaGHKMV11} has shown that it is impossible to eliminate expensive synchronization in classic and ubiquitous specifications, which raises the question of whether it is possible to bypass this impossibility result in any way. We have considered two possible ways to circumvent this result: (1) by considering relaxed semantics and (2) by making additional assumptions about the model.


%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../../main"
%%% End:
